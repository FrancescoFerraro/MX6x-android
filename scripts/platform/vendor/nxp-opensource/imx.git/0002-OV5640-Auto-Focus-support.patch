From ca8a3ed4da4e11620ebd6c264d4babfb26919944 Mon Sep 17 00:00:00 2001
From: Harshesh Valera <harshesh.v@variscite.com>
Date: Tue, 14 Feb 2023 17:33:26 -0800
Subject: [PATCH 2/3] OV5640 Auto Focus support

Signed-off-by: Harshesh Valera <harshesh.v@variscite.com>
---
 camera/CameraDeviceHWLImpl.cpp        |  14 ++-
 camera/CameraDeviceHWLImpl.h          |   2 +
 camera/CameraDeviceSessionHWLImpl.cpp | 175 ++++++++++++++++++++++++--
 camera/CameraDeviceSessionHWLImpl.h   |  12 ++
 camera/CameraMetadata.cpp             |  23 +++-
 camera/VideoStream.h                  |   4 +
 6 files changed, 212 insertions(+), 18 deletions(-)

diff --git a/camera/CameraDeviceHWLImpl.cpp b/camera/CameraDeviceHWLImpl.cpp
index 271f3b8..e7d31ae 100644
--- a/camera/CameraDeviceHWLImpl.cpp
+++ b/camera/CameraDeviceHWLImpl.cpp
@@ -56,6 +56,10 @@ std::unique_ptr<CameraDeviceHwl> CameraDeviceHwlImpl::Create(
         return nullptr;
     }
 
+    ctrl_fd = open(*mDevPath[0], O_RDWR);
+    if (ctrl_fd < 0) {
+	ALOGE("%s invalid fd handle", __func__);
+    }
     ALOGI("%s: Created CameraDeviceHwlImpl for camera %u", __func__, device->camera_id_);
 
     return std::unique_ptr<CameraDeviceHwl>(device);
@@ -72,6 +76,8 @@ CameraDeviceHwlImpl::CameraDeviceHwlImpl(
         mUseCpuEncoder(use_cpu_encoder),
         physical_device_map_(std::move(physical_devices))
 {
+    if (ctrl_fd > 0)
+       close(ctrl_fd);
     mDevPath = devPaths;
     for (int i = 0; i < (int)mDevPath.size(); ++i) {
         ALOGI("%s, mDevPath[%d] %s", __func__, i, *mDevPath[i]);
@@ -219,11 +225,10 @@ status_t CameraDeviceHwlImpl::Initialize()
 
 status_t CameraDeviceHwlImpl::initSensorStaticData()
 {
-    int32_t fd = open(*mDevPath[0], O_RDWR);
-
+    int32_t fd = ctrl_fd;
     if (fd < 0) {
-        ALOGE("ImxCameraCameraDevice: initParameters sensor has not been opened");
-        return BAD_VALUE;
+	    ALOGE("ImxCameraCameraDevice: initParameters sensor has not been opened");
+	    return BAD_VALUE;
     }
 
     // first read sensor format.
@@ -328,7 +333,6 @@ status_t CameraDeviceHwlImpl::initSensorStaticData()
     setMaxPictureResolutions();
     ALOGI("mMaxWidth:%d, mMaxHeight:%d", mMaxWidth, mMaxHeight);
 
-    close(fd);
     return NO_ERROR;
 }
 
diff --git a/camera/CameraDeviceHWLImpl.h b/camera/CameraDeviceHWLImpl.h
index 1aea5a6..c4f4b1e 100644
--- a/camera/CameraDeviceHWLImpl.h
+++ b/camera/CameraDeviceHWLImpl.h
@@ -85,6 +85,8 @@ public:
 
     CameraSensorMetadata* getSensorData() { return &mSensorData; }
 
+    int ctrl_fd;
+
     static bool StreamCombJudge(const StreamConfiguration& stream_config,
         int *pPreviewResolutions, int nPreviewResolutionCount, int *pPictureResolutions, int nPictureResolutionCount);
 
diff --git a/camera/CameraDeviceSessionHWLImpl.cpp b/camera/CameraDeviceSessionHWLImpl.cpp
index 1312fee..601a20b 100644
--- a/camera/CameraDeviceSessionHWLImpl.cpp
+++ b/camera/CameraDeviceSessionHWLImpl.cpp
@@ -100,7 +100,7 @@ status_t CameraDeviceSessionHwlImpl::Initialize(
 {
     int ret;
     camera_id_ = camera_id;
-
+    m_dev = pDev;
     static_metadata_ = std::move(pMeta);
 
     if (pDev == NULL)
@@ -125,19 +125,24 @@ status_t CameraDeviceSessionHwlImpl::Initialize(
 
         if (strstr(cam_metadata->camera_name, UVC_NAME)) {
             pVideoStreams[i] = new UvcStream(*mDevPath[i], this);
+            pVideoStreams[i]->af_supported = false;
         } else if(strstr(cam_metadata->camera_name, ISP_SENSOR_NAME)) {
             pVideoStreams[i] = new ISPCameraMMAPStream(this);
+            pVideoStreams[i]->af_supported = false;
             ((ISPCameraMMAPStream *)pVideoStreams[i])->createISPWrapper(*mDevPath[i], &mSensorData);
         } else if (cam_metadata->buffer_type == CameraSensorMetadata::kMmap) {
             pVideoStreams[i] = new MMAPStream(this);
+            pVideoStreams[i]->af_supported = false;
         } else if (cam_metadata->buffer_type == CameraSensorMetadata::kDma) {
             pVideoStreams[i] = new DMAStream((bool)cam_metadata->mplane, this);
+	    pVideoStreams[i]->af_supported = true;
         } else {
             ALOGE("%s: unsupported camera %s, or unsupported buffer type %d", __func__, cam_metadata->camera_name, cam_metadata->buffer_type);
             return BAD_VALUE;
         }
 
-        ALOGI("%s: VideoStream[%d] %p created, device path %s", __func__, i, pVideoStreams[i], *mDevPath[i]);
+        ALOGE("%s: VideoStream[%d] %p created, device path %s", __func__, i, pVideoStreams[i], *mDevPath[i]);
+        ALOGE("%s: cam_metadata->camera_name %s  af_supported=%d", __func__, cam_metadata->camera_name, pVideoStreams[i]->af_supported);
 
         if (pVideoStreams[i] == NULL)
             return BAD_VALUE;
@@ -1338,17 +1343,58 @@ status_t CameraDeviceSessionHwlImpl::HandleMetaLocked(std::unique_ptr<HalCameraM
 
     resultMeta->Set(ANDROID_CONTROL_AE_PRECAPTURE_ID, &m3aState.aeTriggerId, 1);
 
-    ret = resultMeta->Get(ANDROID_CONTROL_AF_TRIGGER_ID, &entry);
-    if (ret != NAME_NOT_FOUND) {
-        m3aState.afTriggerId = entry.data.i32[0];
-    }
-
-    resultMeta->Set(ANDROID_CONTROL_AF_TRIGGER_ID, &m3aState.afTriggerId, 1);
-
     resultMeta->Set(ANDROID_SENSOR_TIMESTAMP, (int64_t *)&timestamp, 1);
 
     // auto focus control.
-    m3aState.afState = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    resultMeta->Get(ANDROID_CONTROL_AF_MODE, &entry);
+    if (entry.count == 0) {
+        ALOGE("%s: No AF mode entry!", __FUNCTION__);
+        return BAD_VALUE;
+    }
+    uint8_t afMode = (entry.count > 0) ?
+        entry.data.u8[0] : (uint8_t)ANDROID_CONTROL_AF_MODE_OFF;
+    ret = resultMeta->Get(ANDROID_CONTROL_AF_TRIGGER, &entry);
+    if (entry.count > 0) {
+        // save trigger value
+        uint8_t trigger = entry.data.u8[0];
+
+        // check if a ROI has been provided
+        ret = resultMeta->Get(ANDROID_CONTROL_AF_REGIONS, &entry);
+        if (entry.count > 0) {
+            int xavg = (entry.data.i32[0] + entry.data.i32[2]) / 2;
+            int yavg = (entry.data.i32[1] + entry.data.i32[3]) / 2;
+            ALOGV("%s: AF region: x %d y %d", __FUNCTION__, xavg, yavg);
+            setAutoFocusRegion(xavg, yavg);
+        }
+
+        // get and save trigger ID
+        ret = resultMeta->Get(ANDROID_CONTROL_AF_TRIGGER_ID, &entry);
+        if (entry.count > 0)
+            m3aState.afTriggerId = entry.data.i32[0];
+
+        // process trigger type
+        //ALOGV("trigger: %d afMode %d afTriggerId %d", trigger, afMode, m3aState.afTriggerId);
+        switch (trigger) {
+            case ANDROID_CONTROL_AF_TRIGGER_CANCEL:
+                // in case of continuous focus, cancel means to stop manual focus only
+                if ((afMode == ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO) ||
+                    (afMode == ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE))
+                    m3aState.afState = doAutoFocus(afMode);
+                break;
+            case ANDROID_CONTROL_AF_TRIGGER_START:
+                m3aState.afState = doAutoFocus(afMode);
+                break;
+            case ANDROID_CONTROL_AF_TRIGGER_IDLE:
+                m3aState.afState = ANDROID_CONTROL_AF_STATE_INACTIVE;
+                break;
+            default:
+                ALOGE("unknown trigger: %d", trigger);
+                m3aState.afState = ANDROID_CONTROL_AF_STATE_INACTIVE;
+        }
+    } else {
+        m3aState.afState = getAutoFocusStatus(afMode);
+    }
+    resultMeta->Set(ANDROID_CONTROL_AF_TRIGGER_ID, &m3aState.afTriggerId, 1);
     resultMeta->Set(ANDROID_CONTROL_AF_STATE, &m3aState.afState, 1);
 
     // auto white balance control.
@@ -1986,4 +2032,113 @@ int CameraDeviceSessionHwlImpl::getCapsMode(uint8_t sceneMode)
     return 0;
 }
 
+uint8_t CameraDeviceSessionHwlImpl::getAutoFocusStatus(uint8_t mode)
+{
+    struct v4l2_control c;
+    uint8_t ret = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    int result;
+
+    int32_t fd = m_dev->ctrl_fd;
+    if (fd < 0) {
+        ALOGE("getAutoFocusStatus:couldn't open device");
+        return ret;
+    }
+
+    c.id = V4L2_CID_AUTO_FOCUS_STATUS;
+    result = ioctl(fd, VIDIOC_G_CTRL, &c);
+    if (result != 0) {
+        ALOGE("getAutoFocusStatus: ioctl error: %d", result);
+        goto end;
+   }
+
+    switch (c.value) {
+    case V4L2_AUTO_FOCUS_STATUS_BUSY:
+        if ((mode == ANDROID_CONTROL_AF_MODE_AUTO) ||
+            (mode == ANDROID_CONTROL_AF_MODE_MACRO))
+            ret = ANDROID_CONTROL_AF_STATE_ACTIVE_SCAN;
+        else
+            ret = ANDROID_CONTROL_AF_STATE_PASSIVE_SCAN;
+        break;
+    case V4L2_AUTO_FOCUS_STATUS_REACHED:
+        ret = ANDROID_CONTROL_AF_STATE_FOCUSED_LOCKED;
+        break;
+    case V4L2_AUTO_FOCUS_STATUS_FAILED:
+    case V4L2_AUTO_FOCUS_STATUS_IDLE:
+    default:
+        ret = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    }
+end:
+    return ret;
+}
+
+#define OV5640_AF_ZONE_ARRAY_WIDTH	80
+void CameraDeviceSessionHwlImpl::setAutoFocusRegion(int x, int y)
+{
+    struct v4l2_control c;
+    int result;
+    /* Android provides coordinates scaled to max picture resolution */
+
+    for (int i = 0; i < mDevPath.size(); ++i) {
+	    if(pVideoStreams[i]->af_supported) {
+		    //    float ratio = (float)pVideoStream->getWidth() / pVideoStream->getHeight();
+		    float ratio = (float)pVideoStreams[i]->getWidth() / pVideoStreams[i]->getHeight();
+		    int scaled_x = x / (m_dev->mMaxWidth / OV5640_AF_ZONE_ARRAY_WIDTH);
+		    int scaled_y = y / (m_dev->mMaxHeight / (OV5640_AF_ZONE_ARRAY_WIDTH / ratio));
+		    int32_t fd = m_dev->ctrl_fd;
+		    if (fd < 0) {
+	        	ALOGE("setAutoFocusRegion:couldn't open device ");
+		        return;
+    		     }
+
+		    /* Using custom implementation of the absolute focus ioctl for ov5640 */
+		    c.id = V4L2_CID_FOCUS_ABSOLUTE;
+		    c.value = ((scaled_x & 0xFFFF) << 16) + (scaled_y & 0xFFFF);
+		    result = ioctl(fd, VIDIOC_S_CTRL, &c);
+		    if (result != 0)
+		        ALOGE("setAutoFocusRegion:ioctl s ctrl error: %d", result);
+	    }
+    }
+    return;
+}
+
+uint8_t CameraDeviceSessionHwlImpl::doAutoFocus(uint8_t mode)
+{
+    struct v4l2_control c;
+    uint8_t ret = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    int result;
+
+    int32_t fd = m_dev->ctrl_fd;
+    if (fd < 0) {
+        ALOGE("doAutoFocus:couldn't open device ");
+        return ret;
+    }
+
+    switch (mode) {
+    case ANDROID_CONTROL_AF_MODE_AUTO:
+    case ANDROID_CONTROL_AF_MODE_MACRO:
+        ret = ANDROID_CONTROL_AF_STATE_ACTIVE_SCAN;
+        c.id = V4L2_CID_AUTO_FOCUS_START;
+        break;
+    case ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO:
+    case ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE:
+        ret = ANDROID_CONTROL_AF_STATE_PASSIVE_SCAN;
+        c.id = V4L2_CID_FOCUS_AUTO;
+        c.value = 1;
+        break;
+    case ANDROID_CONTROL_AF_MODE_OFF:
+    default:
+        ret = ANDROID_CONTROL_AF_STATE_INACTIVE;
+        c.id = V4L2_CID_AUTO_FOCUS_STOP;
+    }
+    result = ioctl(fd, VIDIOC_S_CTRL, &c);
+    if (result != 0) {
+        ALOGE("doAutoFocus: ioctl error: %d", result);
+        ret = ANDROID_CONTROL_AF_STATE_INACTIVE;
+    }
+
+
+    return ret;
+}
+
+
 }  // namespace android
diff --git a/camera/CameraDeviceSessionHWLImpl.h b/camera/CameraDeviceSessionHWLImpl.h
index e15fd61..da0cec8 100644
--- a/camera/CameraDeviceSessionHWLImpl.h
+++ b/camera/CameraDeviceSessionHWLImpl.h
@@ -36,6 +36,11 @@
 
 using namespace fsl;
 
+// Undefine u8 since the camera_metadata_ro_entry_t contains a u8 field
+#ifdef u8
+    #undef u8
+#endif
+
 namespace android {
 
 using google_camera_hal::CameraDeviceHwl;
@@ -238,6 +243,13 @@ private:
     VideoStream* GetVideoStreamByPhysicalId(uint32_t physical_id);
     PipelineInfo* GetPipelineInfo(uint32_t id);
 
+private:
+    CameraDeviceHwlImpl *m_dev;
+
+    uint8_t doAutoFocus(uint8_t mode);
+    uint8_t getAutoFocusStatus(uint8_t mode);
+    void setAutoFocusRegion(int x, int y);
+
 private:
     class WorkThread : public Thread
     {
diff --git a/camera/CameraMetadata.cpp b/camera/CameraMetadata.cpp
index 9c6676f..b1380a7 100644
--- a/camera/CameraMetadata.cpp
+++ b/camera/CameraMetadata.cpp
@@ -76,7 +76,7 @@ status_t CameraMetadata::createMetadata(CameraDeviceHwlImpl *pDev, CameraSensorM
                      android_control_ae_compensation_step,
                      ARRAY_SIZE(android_control_ae_compensation_step));
 
-    int32_t android_control_max_regions[] = {/*AE*/ 0, /*AWB*/ 0, /*AF*/ 0};
+    int32_t android_control_max_regions[] = {/*AE*/ 0, /*AWB*/ 0, /*AF*/ 1};
     m_static_meta->Set(ANDROID_CONTROL_MAX_REGIONS,
                      android_control_max_regions,
                      ARRAY_SIZE(android_control_max_regions));
@@ -93,6 +93,15 @@ status_t CameraMetadata::createMetadata(CameraDeviceHwlImpl *pDev, CameraSensorM
                      ARRAY_SIZE(android_jpeg_max_size));
 
     /* android.lens */
+    float minFocusDistance[] = {1.0/0.05}; /* 5cm */
+    m_static_meta->Set(ANDROID_LENS_INFO_MINIMUM_FOCUS_DISTANCE,
+		   minFocusDistance,
+		   ARRAY_SIZE(minFocusDistance));
+
+    float hypFocusDistance[] = {1.0/0.05}; /* 5cm */
+    m_static_meta->Set(ANDROID_LENS_INFO_HYPERFOCAL_DISTANCE,
+		    hypFocusDistance,
+		    ARRAY_SIZE(hypFocusDistance));
     float android_lens_info_available_focal_lengths[] = {mSensorData.focallength};
     m_static_meta->Set(ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
                      android_lens_info_available_focal_lengths,
@@ -134,6 +143,16 @@ status_t CameraMetadata::createMetadata(CameraDeviceHwlImpl *pDev, CameraSensorM
             android_lens_info_minimum_focus_distance,
             ARRAY_SIZE(android_lens_info_minimum_focus_distance));
 
+
+    const uint8_t availableAfModes[] = {
+        ANDROID_CONTROL_AF_MODE_OFF,
+        ANDROID_CONTROL_AF_MODE_AUTO,
+        ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE,
+        ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO,
+    };
+    m_static_meta->Set(ANDROID_CONTROL_AF_AVAILABLE_MODES, availableAfModes,
+		    ARRAY_SIZE(availableAfModes));
+
     /* android.request */
     int32_t android_request_max_num_output_streams[] = {0, 3, 1};
     m_static_meta->Set(ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
@@ -537,8 +556,6 @@ status_t CameraMetadata::createMetadata(CameraDeviceHwlImpl *pDev, CameraSensorM
     static const uint8_t availableAeModes[] = {ANDROID_CONTROL_AE_MODE_OFF, ANDROID_CONTROL_AE_MODE_ON};
     m_static_meta->Set(ANDROID_CONTROL_AE_AVAILABLE_MODES, availableAeModes, ARRAY_SIZE(availableAeModes));
 
-    static const uint8_t availableAfModes[] = {ANDROID_CONTROL_AF_MODE_OFF};
-    m_static_meta->Set(ANDROID_CONTROL_AF_AVAILABLE_MODES, availableAfModes, ARRAY_SIZE(availableAfModes));
 
     static const uint8_t availableAwbModes[] = {
         ANDROID_CONTROL_AWB_MODE_OFF,
diff --git a/camera/VideoStream.h b/camera/VideoStream.h
index 4225f43..1e7d758 100644
--- a/camera/VideoStream.h
+++ b/camera/VideoStream.h
@@ -35,6 +35,10 @@ public:
     int32_t closeDev();
 //    int32_t flushDev();
 
+    int32_t getWidth() {return mWidth;}
+    int32_t getHeight() {return mHeight;}
+
+    bool af_supported;
     void setOmitFrameCount(uint32_t omitCount) { mOmitFrmCount = omitCount; }
 
     // get buffer from V4L2.
-- 
2.25.1

